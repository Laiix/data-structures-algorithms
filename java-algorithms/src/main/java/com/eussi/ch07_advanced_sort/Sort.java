package com.eussi.ch07_advanced_sort;


import com.eussi.ch07_advanced_sort.util.ArrayIns;
import com.eussi.ch07_advanced_sort.util.ArrayPar;
import com.eussi.ch07_advanced_sort.util.ArraySh;
import com.eussi.util.Util;

/**
 * @author wangxueming
 * @create 2020-01-13 16:25
 * @description
 */
public class Sort {
    /**
     *      本章包含了两个高级的排序算法:希尔排序和快速排序。这两种排序算法都比简单排序算法快
     * 得多:希尔排序大约需要O(N*(logN)^2)时间,快速排序需要O(N*1ogN)时间。这两种排序算法都和
     * 归并排序不同,不需要大量的辅助存储空间。希尔排序几乎和归并排序一样容易实现,而快速排序
     * 是所有通用排序算法中最快的一种排序算法。本章的最后还简要地介绍了基数排序,它是一种不常
     * 用但很有趣的排序算法。
     */

    public static void main(String[] args) {
        /**
         * 希尔排序
         *      希尔排序因计算机科学家 Donald L.Shell而得名,他在1959年发现了希尔排序算法。希尔排序
         * 基于插入排序,但是增加了一个新的特性,大大地提高了插入排序的执行效率。
         *      依靠这个特别的实现机制,希尔排序对于多达几千个数据项的,中等大小规模的数组排序表现
         * 良好。希尔排序不像快速排序和其他时间复杂度为O(N*1ogN)的排序算法那么快,因此对非常大的
         * 文件排序,它不是最优选择。但是,希尔排序比选择排序和插入排序这种时间复杂度为O(N2)的排
         * 序算法还是要快得多,并且它非常容易实现:希尔排序算法的代码既短又简单。
         *      它在最坏情况下的执行效率和在平均情况下的执行效率相比没有差很多。(在本章的后面将谈
         * 到,除非采取了预防措施,否则快速排序在最坏情况下的执行效率会非常差。)一些专家提倡差不多任
         * 何排序工作在开始时都可以使用希尔排序算法,若在实际中证明它不够快,再改换成诸如快速排序这样
         * 更高级的排序算法。
         *
         * 插入排序:复制的次数太多
         *      由于希尔排序是基于插入排序的,所以需要回顾一下第3章中的"插入排序"一节。回想一下
         * 在插入排序执行的一半的时候,标记符左边数据项都是排过序的(这些数据项之间是有序
         * 的),而标记右边的数据项则没有排过序。这个算法取出标记符所指的数据项,把它存储在一个临
         * 时变量里。接着,从刚刚被移除的数据项的左边第一个单元开始,每次把有序的数据项向右移动一
         * 个单元,直到存储在临时变量里的数据项能够有序回插。
         *      下面是插入排序带来的问题。假设一个很小的数据项在很靠近右端的位置上,这里本来应该是
         * 值比较大的数据项所在的位置。把这个小数据项移动到在左边的正确位置上,所有的中间数据项(这
         * 个数据项原来所在的位置和它应该移动到的位置之间的数据项)都必须向右移动一位。这个步骤对
         * 每个数据项都执行了将近N次的复制。虽不是所有数据项都必须移动N个位置,但是数据项平
         * 均移动了N/2个位置,这就执行了N次N/2个移位,总共是N^2/2次复制。因此,插入排序的执行
         * 效率是O(N^2)
         *      如果能以某种方式不必一个一个地移动所有中间的数据项,就能把较小的数据项移动到左边,
         * 那么这个算法的执行效率就会有很大的改进。
         *
         * n-增量排序
         *      希尔排序通过加入插入排序中元素之间的间隔,并在这些有间隔的元素中进行插入排序,从而
         * 使数据项能大跨度地移动。当这些数据项排过一趟序后,希尔排序算法减小数据项的间隔再进行排
         * 序,依此进行下去。进行这些排序时数据项之间的间隔被称为增量,并且习惯上用字母h来表示
         *      注意,假如对10个数据项完成以4为增量的希尔排序后,所有元素离它在最终有序序列中的位
         * 置相差很少的单元。这就是数组"基本有序"的含义,也正是希尔排序的奥秘所在。通过创建
         * 这种交错的内部有序的数据项集合,把完成排序所必需的工作量降到了最小。
         *      正如在第3章中所讲的那样,插入排序对基本有序的数组排序是非常有效的。如果插入排序只
         * 需要把数据项移动一位或者两位,那么算法大概需要O(N)时间。这样,当数组完成4-增量排序之
         * 后,可以进行普通的插入排序,即1增量排序。4增量排序和1增量排序结合起来应用,比前面不
         * 执行4-增量排序而仅仅应用曾通的插入排序要快得多。
         *
         * 减小间隔
         *      上面说了以4为初始间隔对包含10个数据项的数组进行排序的情况。对于更大的数组,
         * 开始的间隔也应该更大。然后间隔不断减小,直到间隔变成1
         *      举例来说,含有1000个数据项的数组可能先以364为增量,然后以121为增量,以40为增量,
         * 以13为增量,以4为增量,最后以1为增量进行希尔排序。用来形成间隔的数列(在本例中为364,
         * 121,40,13,4,1)被称为间隔序列。这里所表示的间隔序列由 Knuth提出,此序列
         * 是很常用的。数列以逆向的形式从1开始,通过递归表达式
         *      h = 3*h + 1
         * 来产生，初始值为 1。
         *
         * Knuth间隔序列：
         *      h                   3*h+1                  (h-1)/3
         *      1                   4
         *      4                   13                      1
         *      13                  40                      4
         *      40                  121                     13
         *      121                 364                     40
         *      364                 1093                    121
         *      1093                3280                    363
         *
         *      还有一些其他的方法也能产生间隔序列;后面会讲到这个问题。首先,来研究使用 Knuth序列
         * 进行希尔排序的情况。
         *      在排序算法中,首先在一个短小的循环中使用序列的生成公式来计算出最初的间隔。h值最初
         * 被赋为1,然后应用公式h=3*h+1生成序列1,4,13,40,121,364,等等。当间隔大于数组大
         * 小的时候这个过程停止。对于一个含有1000个数据项的数组,序列的第七个数字,1093就太大了
         * 因此,使用序列的第六个数字作为最大的数字来开始这个排序过程,作364增量排序。然后,每完
         * 成一次排序例程的外部循环,用前面提供的此公式的倒推式来减小间隔:
         * h=(h-1)/3
         *      它在上表的第三栏中显示。这个倒推的公式生成逆置的序列364,121,40,13,4,1。从364
         * 开始,以每一个数字作为增量进行排序。当数组用1-增量排序后,算法结束。
         *
         */
        shellSort(10);
        Util.printSeparator();

        /**
         * 其他间隔序列
         *      选择间隔序列可以称得上是一种魔法。至此只讨论了用公式h=h*3+1生成间隔序列,但
         * 是应用其他间隔序列也取得了不同程度的成功。只有一个绝对的条件,就是逐渐减小的间隔最后
         * 定要等于1,因此最后一趟排序是一次普通的插入排序。
         *      在希尔的原稿中,他建议初始的间距为N/2,简单地把每一趟排序分成了两半。因此,对于N
         * 100的数组逐渐减小的间隔序列为50,25,12,6,3,1。这个方法的好处是不需要在开始排序前
         * 为找到初始的间隔而计算序列;而只需要用2整除N。但是,这被证明并不是最好的数列。尽管对
         * 于大多数的数据来说这个方法还是比插入排序效果好,但是这种方法有时会使运行时间降到O(N^2),
         * 这并不比插入排序的效率更高
         *      这个方法的一个变形是用2.2而非2来整除每一个间隔。对于n=100的数组来说,会产生序列
         * 45,20,9,4,1。这比用2整除显著改善了效果,因为这样避免了某些导致时间复杂度为O(N^2)
         * 的最坏情况的发生。不论N为何值,都需要一些额外的代码来保证序列的最后取值为1。这产生了
         * 和清单中所列的 Knuth序列差不多的结果。
         *      递减数列(来自 Flaming)的另一个可能是
         *      if(h<5)
         *          h=1;
         *      else
         *          h=(5*h-1)/11
         *      间隔序列中的数字互质通常被认为很重要;也就是说,除了1之外它们没有公约数。这个约束
         * 条件使每一趟排序更有可能保持前一趟排序已排好的效果。希尔最初以N/2为间隔的低效性就是归
         * 咎于它没有遵守这个准则
         *      或许还可以设计出像如上讲述的间隔序列一样好的(甚至更好的)间隔序列。但是不管这个间
         * 隔序列是什么,都应该能够快速地计算,而不会降低算法的执行速度
         *
         * 希尔排序的效率
         *      迄今为止,除了在一些特殊的情况下,还没有人能够从理论上分析希尔排序的效率。有各种各
         * 样基于试验的评估,估计它的时间级从O(N^3/2)到O(N^7/6)。
         *      下表对比速度较慢的插入排序和速度较快的快速排序,列出了希尔排序一些估计的O()值。它
         * 显示了对应于不同N值的理论时间。注意N^x/y的意思是N的x方的y次方根。因此,如果N等于
         * 100,N^3/2就是100^3的平方根,结果是1000。另外,(logN)^2意思是N对数的平方。它通常写作log^(2)N,
         * 但这很容易和log2N(以2为底的N的对数)混淆。
         *      希尔排序运行时间的估计
         *      O()值          排序类型            10项         100项        1000项           10000项
         *      N^2             插入等             100         10000       1000000         100000000
         *      N^3/2           希尔排序            32          1000        32000           1000000
         *      N*(logN)^2      希尔排序            10          400         9000            160000
         *      N^5/4           希尔排序            18          316         5600            100000
         *      N^7/6           希尔排序            14          215         3200            46000
         *      N*logN          快速排序等           10          200         3000            40000
         *      对大多数数据来说,评估值越高,如N^3/2,很可能就越真实。
         */

        /**
         * 划分
         *      划分是后面将要讨论的快速排序的根本机制,但是划分本身也是一个有用的操作,因此把它作
         * 为单独的一节在这里讲解。
         *      划分数据就是把数据分为两组,使所有关键字大于特定值的数据项在一组,使所有关键字小于
         * 特定值的数据项在另一组。
         *      很容易想像划分数据的情况。比如可以将职员记录分为两组:家住距离办公地点15英里以内
         * 的雇员和住在15英里以外的雇员。或者学校管理者想要把学生分成年级平均成绩高于3.5和低于
         * 3.5的两组,以此来判定哪些学生应该在系主任掌握的名单里。
         *      在完成划分之后,数据还不能称为有序;这只是把数据简单地分成了两组。但是,数据还是比
         * 没有划分之前要更接近有序了。在下一节中将会看到,要使它完全有序并不会很麻烦
         *      注意划分是不稳定的。这也就是说,每一组中的数据项并不是按照它原来的顺序排列的。事实
         * 上,划分往往会颠倒组中一些数据的顺序
         *
         *
         * 划分算法
         *      划分算法由两个指针开始工作,两个指针分别指向数组的两头。(这里使用“指针”这个词是
         * 指示数组数据项的,而不是C++中所说的指针。)在左边的指针, leftPtr,向右移动,而在右边的指
         * 针, rightPtr,向左移动。
         *      实际上, leftPtr初始化时是在第一个数据项的左边一位, rightPtr是在最后一个数据项的右边一
         * 位,这是因为在它们工作之前,它们都要分别的加一和减一
         *
         * 停止和交换
         *      当leftPtr遇到比枢纽小的数据项时,它继续右移,因为这个数据项的位置已经处在数组的正确
         * 边了。但是,当遇到比枢纽大的数据项时,它就停下来。类似的,当 rightPtr遇到大于枢纽的数
         * 据项时,它继续左移,但是当发现比枢纽小的数据项时,它也停下来。两个内层的while循环,第
         * 个应用于 leftPtr,第二个应用于rightPtr,控制这个扫描过程。因为指针退出了while循环,所以
         * 它停止移动。当两个循环都退出之后，leftPtr和rightPtr都指在数组的错误位置上的数据项，所
         * 以交换两个数据项。
         *      交换之后,继续移动两个指针,当指向的数据项在数组的错误一方时,再次停止,然后交换数
         * 据项。所有的这些操作都包含在一个外部循环中。当两个指针最终相遇的时候,划分过程结束,并且
         * 退出这个外层 while循环。
         *
         * 处理异常数据
         *      如果肯定数组最右端的数据项小于枢纽,并且数组最左端的数据项大于枢纽,那么前面看到的
         * 简化的 while循环会很好地执行。遗憾的是,可能用算法来划分的那些数据没有排列得这么好。
         *      例如,如果所有的数据都小于枢纽, leftPtr变量将会遍历整个数组,徒劳地寻找大于枢纽的数
         * 据项,然后跑出数组的最右端,产生数组越界的异常。当所有的数据都大于枢纽的时候,类似的糟
         * 糕结果也会发生在 rightPtr上。
         *      为了避免这些问题,必须在 while循环中增加数组边界的检测:在第一个循环中增加
         * leftPtr<rightPtr,第二个循环中增加 rightPtr>leftPtr。
         *      在快速排序一节,可以看到更为巧妙的枢纽选择过程,它可以去掉这种数组越界的检测。要使
         * 程序运行速度更快,在内部循环中削减代码总是一个好方法。
         *
         * 精巧的代码
         *      这个whie循环中的代码相当精巧。举例来说,想要从内部循环条件中除去加1操作符,并且
         * 用这个加1操作符代替空操作指令语句。(空操作指令指只包括一个分号的语句,它表示不做任何
         * 操作。)例如,可以把如下的代码:
         *      while(leftPtr < right && theArray[++leftPtr] < pivot)
         *          ;   //(nop)
         *      改为
         *      while(leftPtr < right && theArray[leftPtr] < pivot
         *          ++leftPtr;
         *      对于另一个内部 while循环的改变是相似的。这些改变使指针的初始值分别设为left和 right成
         * 为可能,这比设为left-1和 right+1要更为清晰。
         *      但是,这些改变导致只有在满足条件的情况下指针才会加1。指针在任何情况下都必须移动,
         * 所以需要在外层的 while循环中增加两个附加的语句强迫指针变化。空操作指令是最有效的解决办
         * 法;
         */
        partion(16);
        Util.printSeparator();
        /**
         * 相等的关键字
         *      下面是要在 partitionIt()方法中做的另一个细微的改变。如果想要对所有与枢纽相等的数据项运
         * 行 partitionIt()方法,将发现每一次比较都会产生一次交换。交换关键字相等的数据项看起来是浪费
         * 时间的。 while循环中对枢纽和数组数据项进行比较的<和>操作符产生了这种额外的交换。然而,
         * 假设用<=和>=操作符代替<和>操作符,这确实防止了相等数据项的交换,但是这也使得在算法结束
         * 时leftPtr和 rightPtr停在了数组的两端。正如将要在快速排序一节看到的一样,指针最后最好停在
         * 数组的中间,停在数组的两端是非常糟糕的。因此,如果在快速排序中使用partitionIt()方法,使用
         * <和>操作符是正确的,即便这会引起一些不必要的交换。
         *
         * 划分算法的效率
         *      划分算法的运行时间为O(N):两个指针开始时分别在数组的两端,然后以或大或小的恒定速度相向移动,
         * 停止移动并且在移动的过程中交换。当两个指针相遇时,划分完成。如果要划分两倍数目的数据项,指针以同
         * 样的速率移动,但是需要比较和交换两倍数目的数据项,因此这个过程耗时也是两倍。从而,运行时间和N成正比。
         *      更为特别的,每一次划分都有N+1或者N+2次的比较。每个数据项都由这个或者那个指针指
         * 引参与比较,这产生了N次比较,但是在指针发现它们已经彼此“越过”之前,它们已经移动过头          ?????越过之前判断break不止一次或者两次比较吧？
         * 了,所以在划分完成之前多了一次或者两次额外的比较。比较的次数不取决于数据是如何排列的(除
         * 了在扫描结東时的一次或者两次额外比较的不确定性)
         *      但是,交换的次数确实是取决于数据是如何排列的。如果数据是逆序排列的,并且取的枢纽把
         * 数据项分为两半,那么每一对值都需要交换,也就是N/2次交换。
         *      对于任意的数据,在一次划分中交换的次数将小于N/2,即使一半的竖条小于枢纽,一半的竖条
         * 大于枢纽。这是因为总会有一些竖条在正确的位置上(短的竖条在左面,长的竖条在右面)。如果枢
         * 纽比大多数的竖条都大(或者小),会有更少的交换次数,这是因为只有很少的大于(或者小于)枢
         * 纽的竖条需要交换。对于任意的数据,在平均情况下,大约执行数据项最大数目的一半的交换操作。
         *      尽管交换的次数少于比较的次数,但它们都是和N成正比的。因此,划分过程运行O(N)时间。
         */

        /**
         * 快速排序
         *      亳无疑问,快速排序是最流行的排序算法,因为有充足的理由,在大多数情况下,快速排序都
         * 是最快的,执行时间为O(N*logN)级。(这只是对内部排序或者说随机存储器内的排序而言,对于
         * 在磁盘文件中的数据进行的排序,其他的排序算法可能更好。)快速排序是在1962年由CAR. Hoare
         * 发现的。
         *      为了理解快速排序算法,对于前面一节所描述的划分算法应该非常熟悉。快速排序算法本质上
         * 通过把一个数组划分为两个子数组,然后递归地调用自身为每一个子数组进行快速排序来实现的。
         * 但是,对这个基本的设计还需要进行一些加工。算法还必须要选择枢纽以及对小的划分区域进行排
         * 序。看过这个主要算法的简化代码以后,还要对其进行求精。
         *      在理解快速排序的道理之前想知道快速排序干的是什么,这一点有困难,所以在这里颠倒通常
         * 的讲解顺序,先列出快速排序的Java代码。
         */
        quickSort1();
        Util.printSeparator();
        /**
         * 如上面代码，有三个步骤：
         *      1.把数组或者子数组划分成左边(较小的关键字)的一组和右边(较大的关键字)的一组
         *      2.调用自身对左边的一组进行排序。
         *      3.再次调用自身对右边的一组进行排序。
         * 经过一次划分之后,所有在左边子数组的数据项都小于在右边子数组的数据项。只要对左边子
         * 数组和右边子数组分别进行排序,整个数组就是有序的了,如何对子数组进行排序呢?通过递归的
         * 调用排序算法自身就可以。
         *      传递给 recQuickSort()方法的参数决定了要排序数组(或者子数组)的左右两端的位置。这个方
         * 法首先检查数组是否只包含一个数据项。如果数组只包含一个数据项,那么就定义数组已经有序,
         * 方法立即返回。这是这个递归过程的基值(终止)条件
         *      如果数组包含两个或者更多的数据项,算法就调用在前面一节中讲过的 partitionlt()方法对这个
         * 数组进行划分。方法返回分割边界的下标数值(partition),它指向右边(较大的关键字)子数组最
         * 左端的数据项。划分标记给出两个子数组的分界。
         *      对数组进行划分之后, recQuickSort(递归地调用自身,数组左边的部分调用一次,对从left到
         * partition-1位置上的数据项进行排序,数组右边的部分也调用一次,对从 partition+1到 right位置上
         * 的数据项进行排序。注意这两个递归调用都不包含数组下标为paritition的数据项。为什么不包含这
         * 个数据项呢?难道下标为 partition的数据项不需要排序吗?这个原因在于枢纽的选择方法
         *
         * 选择枢纽
         *      partitionIt()方法应该使用什么样的枢纽呢?以下是一些相关的思想
         *          - 应该选择具体的一个数据项的关键字的值作为枢纽;称这个数据项为 pivot(枢纽)
         *          - 可以选择任意一个数据项作为枢纽。为了简便,我们假设总是选择待划分的子数组最右端的数据项作为枢纽。
         *          - 划分完成之后,如果枢纽被插入到左右子数组之间的分界处,那么枢纽就落在排序之后的最终位置上了。
         *      最后一条听起来似乎是不可能的,但请记住,正是因为使用枢纽的关键字的值来划分数组,所
         * 以划分之后的左边子数组包含的所有数据项都小于枢纽,右边子数组的所有数据项都大于枢纽。枢
         * 纽开始时在右端,但是如果以某种方式把它放在两个子数组之间,枢纽就会在正确的位置上了,也就是说,在
         * 它最终排序的位置上了。如上面代码，通过修改partitionIt()方法将枢纽排除在外。
         *      在 partitionIt()方法中有趣的一点是,可以删除第一个内部 while循环中对是否超越数组右端的
         * 检测。在之前的划分代码中partitionIt()方法中的这个检测,即
         *      leftPtr < right
         *      在没有大于枢组的数据项时,它防止了leftPtr右移越过数组的右端。为什么可以去除这个检测
         * 呢?这是因为选择最右端的数据项作为枢纽,所以 leftEr总会停在枢纽这个位置上。但是,第二个    //因为 最右边的数据小于pivot总是不成立，退出while循环
         * while循环中的 rightPtr仍然需要这个检测。(后面会讲如何同样地消除这个检测。)
         *      选择最右端的数据项作为枢纽不属于完全随意的选择,但是这样消除了不必要的检测,以此来
         * 加速代码的执行。选择某个其他位置上的数据项作为枢纽不能体现这个优势
         *
         * 注意的事情
         *      有人可能会认为像快速排序这样的高效的算法应该不能处理只有两三个数据项大小的子数组。
         * 但是,这里讲的快速排序算法可以很好地对如此小的子数组进行排序;只是在 leftScan和 rightScan
         * 相遇之前,它们不会移动很大的距离。因此,对于很小的子数组不需要使用不同的排序方法。(不
         * 过,在后面可以看到,使用不同的方法处理很小的子数组可能会有很多好处。)
         *
         * 性能降到了O(n^2)
         *      对100个逆序的竖条排序,会发现算法运行得极其缓慢。这里发生了什么呢?
         *      问题出在枢纽的选择上。理想状态下,应该选择被排序的数据项的中值数据项作为枢纽。也就
         * 是说,应该有一半的数据项大于枢纽,一半的数据项小于枢纽。这会使数组被划分成两个大小相等
         * 的子数组。对快速排序算法来说拥有两个大小相等的子数组是最优的情况。如果快速排序算法必须
         * 要对划分的一大一小两个子数组排序,那么将会降低算法的效率,这是因为较大的子数组必须要被
         * 划分更多次。
         *      N个数据项数组的最坏的划分情况是一个子数组只有一个数据项,另一个子数组含有N-1个数
         * 据项。(这种划分为1个数据项与N-1个数据项的情况)，如果在每一趟划分中都出现这种1个数据项
         * 和N-1个数据项的分割,那么每一个数据项都需要一次单独的划分步骤。在逆序排列的数据项中实际
         * 上发生的就是这种情况:所有的子数组中,枢纽都是最小的数据项,因此每一次划分都产生一个有N-1
         * 个数据项的子数组以及另外一个只包含枢纽的子数组。在这种情况下,划分所带来的好处都没有了,算
         * 法的执行效率降低到O(N^2)
         *      快速排序以O(N^2)运行的时候,除了慢还有另外的一个潜在的问题。当划分的次数增加的时候
         * 递归方法的调用次数也增加了。每一个方法调用都要增加所需递归工作栈的大小。如果调用次数太
         * 多,递归工作栈可能会发生溢出,从而使系统瘫痪
         *      总之:选择最右端的数据项作为枢纽。如果数据项真的是任意排列的那么这个选择不会太坏,因
         * 为通常情况下枢纽不会太靠近数组的两端。但是,当数据是有序的或者是逆序时,从数组的一端或者另
         * 外一端选择数据项作为枢纽都不是好办法。能改进选择枢纽的方法吗？
         *
         * “三数据项取中”划分
         *      人们已经设计出了很多选择更好的枢纽的方法。方法应该简单但能避免出现选择最大或者最小
         * 数据项作为枢纽的情况。选择任意一个数据项作为枢纽的确是很简单的,但是正如我们已经看到的
         * 那样,这并不总是一个好的选择。可以检测所有的数据项,并且实际计算哪一个数据项是中值数据
         * 项。这应该是理想的枢纽选择,可是由于这个过程需要比排序本身更长的时间,因此它不可行
         *      折衷的方法是找到数组里第一个、最后一个以及中间位置数据项的居中数据项值,并且设此数
         * 据项为枢纽。选择第一个、最后一个以及中间位置数据项的中值被称为“三数据项取中”
         * ( median-of- three)方法
         *      查找三个数据项的中值数据项自然比查找所有数据项的中值数据项快很多,同时这也有效地避
         * 免了在数据已经有序或者逆序的情况下,选择最大的或者最小的数据项作为枢纽的机会。很可能存
         * 在一些很特殊的数据排列使得三数据项取中的方法很低效,但是通常情况下,对于选择枢纽它都是
         * 个又快又有效的方法。
         *      三数据项取中方法除了选择枢纽更为有效之外,还有一个额外的好处:可以在第二个内部 while
         * 循环中取消 rightPtr>left的测试,以略微提高算法的执行速度。这是怎样实现的呢?
         *      因为在选择的过程中使用三数据项取中的方法不仅选择了枢纽,而且还对三个数据项进行了排
         * 序,所以可以消除这个测试。
         *      当这三个数据项已经排好序,并且已经选择中值数据项作为枢纽后,这时就可以保证子数组最
         * 左端的数据项小于(或者等于)枢纽,最右端的数据项大于(或者等于)枢纽。这就意味着即使取
         * 消 leftPtr>right和 rightPtr<left的检测, leftPtr和rightPtr也不会分别越过数组的右端或者左端。(指
         * 针停止移动,考虑是否需要交换数据项,只要发现它和另外一个指针位置交叉,则划分过程结束。)
         * left和right的值充当了监视哨，以确保不会使leftPtr和rightPtr超出数组范围。
         *      三数据项取中的另外一个小的好处是,对左端、中间以及右端的数据项排序之后,划分过程就
         * 不需要再考虑这三个数据项了。划分可以从left+1和 right-1开始,因为left和 right已经被有效地
         * 划分了。因为left在左边并且小于枢纽,所以它已经在正确的划分中了, right在右边且大于枢纽,
         * 所以它也在正确的划分中。
         *      这样,三数据项取中的划分方法不但避免了对已有序数据项排序的执行效率为O(N2),而且它
         * 也提高了划分算法内部循环的执行速度,并稍稍减少了必须要划分的数据项数目。
         */
        quickSort2();
        Util.printSeparator();
        /**
         *      程序使用了另一个新方法 manualSort(),对只有三个或者更少数据项的子数组进行排序。当子
         * 数组中只有一个数据项(或者更少)时方法立即返回,有两个数据项时,如果需要则交换这两个数
         * 据项,有三个数据项时对三个数据项进行排序。由于中值划分要求至少含有四个数据项,所以
         * recQuickSort2()例程不能应用于只有两个或者三个数据项的子数组。
         *      使用三数据项取中方式,逆序排列数据排序执行效率大大提高了。每个子数组不再被划分
         * 为1个数据项和N-1个数据项两组了,而是被划分成大致相等的两组。
         *      quickSort2专题 applet除了对有序数据项排序改进了效率之外,其他时候与quickSort1执行效
         * 果相似。它对随机数据排序时并没有执行得更快,只是在对有序数据排序时它的优势才表现出来。
         *
         * 处理小划分
         *      如果使用三数据项取中划分方法,则必须要遵循快速排序算法不能执行三个或者少于三个数据
         * 项的划分的规则。在这种情况下,数字3被称为切割点(cutoff)在上面的例子中,是用一段代码
         * 手动地对两个或三个数据项的子数组来排序的。这是最好的方法吗?
         *
         * 对小划分使用插入排序
         *      处理小划分的另一个选择是使用插入排序。当使用插入排序的时候,不用限制以3为切割点
         * (cutoff)可以把界限定为10、20或者其他任何数。试验不同切割点的值以找到最好的执行效率,
         * 这件事是很有意义的。 Knuth推荐使用9作为切割点。但是,最好的选择值取决于计算机、操作系
         * 统、编译器(或者解释器)等。
         */
        quickSort3();
        /**
         *      在这个特别的算法中,对小的子数组使用插入排序被证实为最快的一种方法,但是它不比在
         * quickSort2中对三个或者更少的数据项的子数组手动地排序快。比较和复制的次数在快速排序
         * 阶段都大大地减少了,但是在插入排序阶段却又上升了差不多相同的次数,因此并没有明显地节省
         * 时间。但是,要想把快速排序的性能发挥到极限,这个方法大概还是有用的。
         *
         * 快速排序之后的插入排序
         *      另一个选择是对数组整个使用快速排序,不去考虑小于界限的划分的排序。在quickSort(方法
         * 中的注释部分表明了这种做法。(如果使用这种做法,那么应该从 recQuickSorto中删除对方法
         * insertion SortO的调用。)当快速排序结束时,数组已经是基本有序的了。然后可以对整个数组应用
         * 插入排序。插入排序对基本有序的数组执行效率很高,而且很多专家都提倡使用这个方法,但是在
         * 我们的设置中,这个方法运行得很慢。插入排序显然更合适做很多小规模的排序,而不是一个大的
         * 排序。
         *
         * 消除递归
         *      很多作者提倡的对快速排序算法的另一个可取的修改是消除递归。这包括重写算法以在栈中存
         * 储递推的子数组的上下界(left和 right),以及使用循环代替递归来执行越来越小的子数组的划分。
         * 这么做的思想是通过取消方法调用来加速算法的执行。但是,这个思想源于早先的编译器以及计算
         * 机体系结构,对于每一次方法调用那种旧的系统都会导致大量的时间消耗。对于现在的系统来说,
         * 消除递归所带来的改进不是很明显,因为现在的系统可以更为有效地处理方法调用。
         *
         * 快速排序的效率
         *      快速排序的时间复杂度为O(N*logN)。正如第6章的归并排序中所讨论的那样,对于分治算法
         * 总的来说都是这样的,在分治算法中用递归的方法把一列数据项分为两组,然后调用自身来分别处
         * 理每一组数据项。这种情况下,算法实际上是以2为底的:运行时间和N*log2(N)成正比。
         */

        /**
         * 基数排序
         *      前面的排序算法都是对简单数值型关键字的处理，处理,也就是通过比较关键字的值来实现排
         * 序的。基数排序则是把关键字拆分成数字位。并且按数字位的值对数据项进行排序。奇怪的是,实现
         * 基数排序不需要比较操作。
         *
         * 基数排序算法
         *      这里讨论的基数排序都是普通的以10为基数的运算,因为这样更易于讲解。但是,以2为基
         * 数实现的基数排序也是非常高效的,这可以利用计算机高速的位运算。这里只考察基数排序,而不
         * 考察与基数排序相似但更复杂些的基数交换排序。基数这个词的意思是一个数字系统的基。10是
         * 十进制系统的基数,2是二进制系统的基数。排序包括分别检测关键字的每一个数字,检测从个位
         * (最低有效位)开始。
         *      1.根据数据项个位上的值,把所有的数据项分为10组。
         *      2.然后对这10组数据项重新排列:把所有关键字是以0结尾的数据项排在最前面,然后是关
         * 键字结尾是1的数据项,照此顺序直到以9结尾的数据项。这个步骤被称为第一趟子排序。
         *      3.在第二趟子排序中,再次把所有的数据项分为10组,但是这一次是根据数据项十位上的值
         * 来分组的。这次分组不能改变先前的排序顺序。也就是说,第二趟排序之后,从每一组数据项的内
         * 部来看,数据项的顺序保持不变;这趟子排序必须是稳定的。
         *      4.然后再把10组数据项重新合并,排在最前面的是十位上为0的数据项,然后是10位为1的
         * 数据项,如此排序直到十位上为9的数据项。
         *      5.对剩余位重复这个过程。如果某些数据项的位数少于其他数据项,那么认为它们的高位为0
         * 下面是一个例子,有7个数据项,每个数据项都有三位。为了清晰起见显示第一位的0
         *      421 240 035 532 305 430 124             // unsorted array
         *      (240 430) (421) (532) (124) (035 305)   // sorted on 1s digit
         *      (305) (421 124) (430 532 035) (240)     //sorted on 10s digit
         *      (035) (124) (240) (305) (421 430) (532) // sorted on 100s digit
         *      035 124 240 305 421 430 532             // sorted array
         *      圆括弧表示组。在同一组中对应位置上的值是相同的。为了证实这种方法是确实可行的,可以
         * 在纸上用几个数字自己动手做一做。
         *
         * 设计一个程序
         *      实际应用中,原始数据很可能是来自于一个普通数组。那么10组数据项存放在哪里呢?可以
         * 利用另外一个数组或者利用一个含有10个数组的数组,但又出现了一个问题。个位,十位,百位
         * 每一位数值的个数不可能完全相同,因此很难确定数组的大小。解决这个问题的一种方法是使用10
         * 个链表,而不用10个数组。链表可以根据需要扩展或收缩。这里将采用这个方法
         *      外层循环依次查看关键字的每一位。有两个内部循环:第一个循环从数组中取得数据项放到链
         * 表中:第二个循环则把数据项从链表复制回数组。这里必须使用一种恰当的链表。为了保证子排序
         * 的稳定,必须保证数据出链表的顺序与进链表的顺序相同。哪一种链表能够方便地做到这一点呢?
         * 具体的代码留作练习。
         *
         * 基数排序的效率
         *      初看起来,基数排序的执行效率似乎好得让人无法相信。所有要做的只是把原始的数据项从数
         * 组复制到链表,然后再复制回去。如果有10个数据项,则有20次复制。对每一位重复一次这个过
         * 程。假设对5位的数字排序,就需要20*5,等于100次复制。如果有100个数据项,那么就有200*5
         * 等于1000次复制。复制的次数和数据项的个数成正比,即O(N),这是我们看到的效率最高的排序
         * 算法
         *      不幸的是,一般是这样:只要数据项越多,就需要越长的关键字。如果数据项增加10倍,那
         * 么关键字就需要再增加另一位。复制的次数是和数据项的个数与关键字的位数的乘积成正比。位数
         * 是关键字值的对数,因此在绝大多数的情况下,算法的执行效率倒退为O(N*logN),和快速排序算
         * 法相同
         *      尽管从数字中提取出每一位需要花费时间,但是没有比较。每两次复制需要一次位提取。然而,
         * 一台给定的计算机在二进制中的位提取操作快于比较操作。当然,与归并排序类似,基数排序所需
         * 要的存储空间是快速排序的二倍
         */
    }

    public static void quickSort3()
    {
        int maxSize = 16;             // array size
        ArrayIns arr;
        arr = new ArrayIns(maxSize);  // create array

        for(int j=0; j<maxSize; j++)  // fill array with
        {                          // random numbers
            long n = (int)(Math.random()*99);
            arr.insert(n);
        }
        arr.display();                // display items
        arr.quickSort3();              // quicksort them
        arr.display();                // display them again
    }  // end main()

    public static void quickSort2()
    {
        int maxSize = 16;             // array size
        ArrayIns arr;
        arr = new ArrayIns(maxSize);  // create array

        for(int j=0; j<maxSize; j++)  // fill array with
        {                          // random numbers
            long n = (int)(Math.random()*99);
            arr.insert(n);
        }
        arr.display();                // display items
        arr.quickSort2();              // quicksort them
        arr.display();                // display them again
    }  // end main()

    public static void quickSort1()
    {
        int maxSize = 16;             // array size
        ArrayIns arr;
        arr = new ArrayIns(maxSize);  // create array

        for(int j=0; j<maxSize; j++)  // fill array with
        {                          // random numbers
            long n = (int)(Math.random()*99);
            arr.insert(n);
        }
        arr.display();                // display items
        arr.quickSort();              // quicksort them
        arr.display();                // display them again
    }  // end main()

    public static void partion(int maxSize) {
        ArrayPar arr = new ArrayPar(maxSize);  // create the array

        for(int j=0; j<maxSize; j++)  // fill array with
        {                          // random numbers
            long n = (int)(Math.random()*199);
            arr.insert(n);
        }
        arr.display();                // display unsorted array

        long pivot = 99;              // pivot value
        System.out.print("Pivot is " + pivot);
        int size = arr.size();
        // partition array
        int partDex = arr.partitionIt(0, size-1, pivot);

        System.out.println(", Partition is at index " + partDex);
        arr.display();                // display partitioned array
    }  // end main()

    public static void shellSort(int maxSize){
        ArraySh arr = new ArraySh(maxSize);   // create the array

        for(int j=0; j<maxSize; j++)  // fill array with
        {                          // random numbers
            long n = (int)(Math.random()*99);
            arr.insert(n);
        }
        arr.display();                // display unsorted array
        arr.shellSort();              // shell sort the array
        arr.display();                // display sorted array
    }  // end main()


}
