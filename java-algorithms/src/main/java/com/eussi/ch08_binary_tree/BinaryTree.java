package com.eussi.ch08_binary_tree;

import com.eussi.ch08_binary_tree.util.Node;
import com.eussi.ch08_binary_tree.util.Tree;

import java.io.IOException;

/**
 * @author wangxueming
 * @create 2020-01-21 14:52
 * @description
 */
public class BinaryTree {
    /**
     * 二叉树是编写程序中使用的一种基本数据结构。他的优势是前面介绍的数据结构所没有的。
     */

    public static void main(String[] args) {
        /**
         * 为什么使用二叉树？
         *      为什么要用到树呢?因为它通常结合了另外两种数据结构的优点:一种是有序数组,另一种
         * 是链表。在树中查找数据项的速度和在有序数组中查找一样快,并且插入数据项和删除数据项的
         * 速度也和链表一样。下面,我们先来稍微思考一下这些话题,然后再深入地研究树的细节。
         *
         * 在有序数组中插入数据项太慢
         *      假设数组中的所有数据项都有序的排列——这就是有序数组,和第2章“数组”中讲过的一样。
         * 本书已经讲过,用二分查找法可以在有序数组中快速地查找特定的值。它的过程是先查看数组的正
         * 中间的数据项,如果那个数据项值比要找的大,就缩小査找范围,在数组的后半段中找;如果小
         * 就在前半段找。反复这个过程,查找数据所需的时间是O(logN)。同时也可以迅速地遍历有序数组,
         * 按顺序访问每个数据项
         *      然而,想在有序数组中插入一个新数据项,就必须首先查找新数据项插入的位置,然后把所有
         * 比新数据项大的数据项向后移动一位,来给新数据项腾出空间。这样多次的移动很费时,平均来讲
         * 要移动数组中一半的数据项(N/2次移动)。删除数据项也需要多次的移动,所以也很慢。
         *      显而易见,如果要做很多的插入和删除操作,就不该选用有序数组。
         *
         * 在链表中查找太慢
         *      另一方面,在第5章“链表”中,链表的插入和删除操作都很快。它们只需要改变一些引用的
         * 值就行了。这些操作的时间复杂度是O(1)(是大O表示法中最小的时间复杂度)
         *      但是遗憾的是,在链表中查找数据项可不那么容易。查找必须从头开始,依次访问链表中的每
         * 个数据项,直到找到该数据项为止。因此,平均需要访问N/2个数据项,把每个数据项的值和要
         * 找的数据项做比较。这个过程很慢,费时O(N)(注意,对排序来说比较快的,对数据结构操作来说
         * 是比较慢的。)。
         *      不难想到可以通过有序的链表来加快查找速度,链表中的数据项是有序的,但这样做是没有用
         * 的。即使是有序的链表还是必须从头开始依次访问数据项,因为链表中不能直接访问某个数据项
         * 必须通过数据项间的链式引用才可以。(当然有序链表访问节点还是比无序链表快多了,但查找任
         * 意的数据项时它也无能为力了。)
         *
         * 用树解决问题
         *      要是能有一种数据结构,既能像链表那样快速的插入和删除,又能像有序数组那样快速査找,
         * 那样就好了。树实现了这些特点,成为最有意思的数据结构之一。
         *
         * 树是什么?
         *      本章中着重讲解的是一种特殊的树——二叉树,但在讲解二叉树之前,还是先从广义上讨论
         * 下树。
         *      树由边连接的节点而构成。
         *      人们把树作为抽象的数学实体来广泛地研究,因此有大量的关于树的理论知识。其实树是范畴
         * 更广的图的特例,不过这里先不考虑图。在第13章“图”和第14章“带权图”将会讨论图
         *      计算机程序里,节点一般代表着那些实体,诸如人、汽车零件、预定的机票等等——这也就是
         * 其他常用的数据结构中存储的那些数据项。像Java这样的面向对象编程语言中,真实世界的实体常
         * 常用对象来表示。
         *      节点间的直线(边)表示关联节点间的路径。一般,用边表示关联是方便的:因为如果节点间
         * 有边作为关联,对程序来说从一个节点到另一个节点是很容易的(也很快)。实际上,从一个节点
         * 到另一个节点的惟一方法是沿着一条顺着有边的道路前进。一般规定顺着边的一个方向走:即从根
         * 向下的方向。
         *      Java语言编写的程序中常常用引用来表示边(或者C/C++程序中可能会用指针)。
         *      在树的顶层总是只有一个节点,它通过边连接到第二层的多个节点,然后第二层节点连向第三
         * 层更多的节点,依此类推。所以树的顶部小,底部大。这和真的树相比好像是颠倒过来了,但程序
         * 般都从树的小的那端开始执行一种操作,而且(可以论证)从顶到底来思考问题更自然,就像人
         * 们阅读文字那样。
         *      树有很多种。不过,这章里将讨论的是一种特殊的树——二叉树。二叉树的每个节点最多有两个子节
         * 点。更普通的树里,节点的子节点可以多于两个,这种树称为多路树。
         *
         * 树的术语
         *      很多术语都可用来描述树的各个部分。为了让介绍的内容更容易理解,需要知道一些树的术语
         * 幸运地是大部分术语都与真实世界的树相关,或者和家庭关系有关(如父节点和子节点),所以它
         * 们记忆起来一点也不难。
         *  - 路径
         *      设想一下顺着连接节点的边从一个节点走到另一个节点,所经过的节点的顺序排列就称为“路
         * 径。
         *  - 根
         *      树顶端的节点称为“根”。一棵树只有一个根。如果要把一个节点和边的集合定义为树,那么
         * 从根到其他任何一个节点都必须有一条(而且只有一条)路径。
         *  - 父节点
         *      每个节点(除了根)都恰好有一条边向上连接到另一个节点,上面的这个节点就称为下面节点的“父
         * 节点”。
         *  - 子节点
         *      每个节点都可能有一条或多条边向下连接其他节点,下面的这些节点就称为它的“子节点”。
         *  - 叶节点
         *      没有子节点的节点称为“叶子节点”或简称“叶节点”。树中只有一个根,但是可以有很多叶
         * 节点。
         *  - 子树
         *      每个节点都可以作为“子树”的根,它和它所有的子节点,子节点的子节点等都含在子树中
         * 就像家族中那样,一个节点的子树包含它所有的子孙。
         *  - 访问
         *      当程序控制流程到达某个节点时,就称为“访问”这个节点,通常是为了在这个节点处执行某
         * 种操作,例如查看节点某个数据字段的值或显示节点。如果仅仅是在路径上从某个节点到另一个节
         * 点时经过了一个节点,不认为是访问了这个节点。
         *  - 遍历
         *      遍历树意味着要遵循某种特定的顺序访问树中所有节点。例如,可以按关键字值的升序访问所
         * 有的节点。当然还有其他的顺序来遍历一棵树,后面将会讲到
         *  - 层
         *      一个节点的层数是指从根开始到这个节点有多少“代”。假设根是第0层,它的子节点就是第1
         * 层,它的孙节点就是第2层,依此类推
         *  - 关键字
         *      可以看到,对象中通常会有一个数据域被指定为关键字值。这个值常用于查询或其他的操作。
         * 在树的图形中,如果用圆表示保存数据项的节点,那么一般将这个数据项的关键字值显示在这个圆
         * 中。
         *  - 二叉树
         *      如果树中每个节点最多只能有两个子节点,这样的树就称为“二叉树”。本章将会着重讲解二
         * 叉树,因为它是最简单的,也是最常用的。
         *      二叉树每个节点的两个子节点称为“左子节点”和“右子节点”,分别对应于树图形中它们的
         * 位置。二叉树中的节点不是必须有两个子节点;它可以只有一个左子节点,或者只
         * 有一个右子节点,或者干脆没有子节点(这种情况下它就是叶节点)
         *      下面我们要学习的这种二叉树在学术上称为二叉搜索树。
         *      注意：
         *          二叉搜索树特征的定义可以这样说:一个节点的左子节点的关键字值小于这个节点,右子
         *      节点的关键字值大于或等于这个父节点
         *
         * 一个类比
         *      计算机系统中,人们常遇到的树是分级文件结构。给定设备的根目录(在许多系统中,通过反
         * 斜线符号指定,如C:\)是树的根。根目录下面的一层目录是根的子节点。子目录有许多层。文件
         * 代表叶节点;它们没有自己的子节点
         *      显然,分级文件结构不是二叉树,因为一个目录下可以有很多子节点。一个完整的路径名称,
         * 如C:\SALES\EAST\NOVEMEBER\SMITH DAT,对应着从根到SMITH.DAT叶的路径。应用于文件
         * 结构的术语,如根和路径等,是从树的理论中借来的
         *      分级文件结构和本章下面要讨论的树有明显的不同。文件结构中,子目录中不含有数据:它们
         * 只有其他子目录或文件的引用。只有文件中包含数据。而在树中,每个节点都包含数据(员工记录、
         * 汽车零件说明等等)。而且除了包含数据,除了叶子节点之外,每个节点还包含指向其他节点的引用。
         *
         * 非平衡树
         *      注意有些树是非平衡的；也就是说，他们大部分的节点在根的一边后者另一边。
         *      树变得不平衡是由数据项插入的顺序造成的。如果关键字值是随机插入的,树会或多或少更平
         * 衡一点。但是,如果插入序列是升序(像11,18,33,42,65,等等)或是降序,则所有的值都是
         * 右子节点(升序时)或者都是左子节点(降序时),这样树就会不平衡了。
         *      如果树中关键字值的输入顺序是随机的,这样建立的较大的树,它的不平衡问题可能不会很严
         * 重,因为很长一列随机数值有序的机会是很小的。不过关键值也可以按一个严格的顺序输入;例如
         * 负责数据录入的人员在输入数据之前,将一堆员工档案按员工号递增的顺序排列。如果这样做,那
         * 么树的效率就会严重退化。第9章中将会讨论不平衡的树以及该如何处理它们。
         *
         * 用Java代码表示树
         *      下面来看看如何用Java语言实现二叉树。像其他数据结构一样,有很多方法可以在计算机内存
         * 中表示树。最常用的方法是把节点存在无关联的存储器中,而通过每个节点中指向自己子节点的引
         * 用来连接
         * 还可以在内存中用数组表示树,用存储在数组中相对的位置来表示节点在树中的位置。本章最
         * 后将讨论这种方法。实例中的Java代码采用的是用引用连接节点的方法。
         */
        tree();
        /**
         * 查找节点树的效率
         *      像上面看到的那样,查找节点的时间取决于这个节点所在的层数。它的时间复杂度是
         * O(logN),更精确地说是O(log2(N)),以2为底的对数。
         *
         * 插入一个节点
         *      要插入节点,必须先找到插入的地方。这很像要找一个不存在的节点的过程,如前面说的找不
         * 到节点的那种情况。从根开始查找一个相应的节点,它将是新节点的父节点。当父节点找到了,新
         * 的节点就可以连接到它的左子节点或右子节点处,这取决于新节点的值是比父节点的值大还是小。
         *
         * 遍历树
         *      遍历树的意思是根据一种特定顺序访问树的每一个节点。这个过程不如查找、插入和删除节点
         * 常用,其中一个原因是因为遍历的速度不是特别快。不过遍历树在某些情况下是有用的,而且在理
         * 论上很有意义。(遍历比删除简单,本章会尽量把删除操作放在后面讨论。)
         *      有三种简单的方法遍历树。它们是:前序( preorder)、中序( inorder)、后序( postorder)
         * 二叉搜索树最常用的遍历方法是中序遍历,所以先来看看中序遍历,再简要地学习其他那两种遍历方
         * 法
         *  - 中序遍历
         *      中序遍历二叉搜索树会使所有的节点按关键字值升序被访问到。如果希望在二又树中创建有序
         * 的数据序列,这是一种方法
         *      遍历树的最简单方法是用递归的方法(第6章中介绍过)。用递归的方法遍历整棵树要用一个
         * 节点作为参数。初始化时这个节点是根。这个方法只需要做三件事:
         *      1.调用自身来遍历节点的左子树
         *      2.访问这个节点
         *      3.调用自身来遍历节点的右子树。
         *      记住访问一个节点意味着对这个节点做某种操作:显示节点,把节点写入文件,或其他别的操作
         *      遍历可以应用于任何二叉树,而不只是二叉搜索树。这个遍历的原理不关心节点的关键字值;
         * 它只是看这个节点是否有子节点。
         *  - 前序和后序遍历
         *      除了中序之外,还有两种遍历方法;它们是前序和后序。要中序遍历一棵树的原因是很清楚的,
         * 但要通过前序或后序来遍历树的目的就不是那么清楚了。不过,如果要编写程序来解析或分析代数
         * 表达式,这两种遍历方法就很有用了。下面来看看为什么是这样的
         *      二叉树(不是二叉搜索树)可以用于表示包括二元运算符号+、一、/、*的算术表达式。根节点
         * 保存运算符号,其他节点或者存变量名(像A、B或C),或者保存运算符号。每一棵子树都是一个
         * 合法的代数表达式。通过前序中序后序遍历可以获取前缀中缀后缀表达式。
         *
         * 查找最大值和最小值
         *      顺便说一下,在二叉搜索树中得到最大值和最小值是轻而易举的事情。事实上,这个过程非常
         * 容易。要找最小值时,先走到根的左子节点处,然后接着走到那个子节点的左子节点,如此类推,直
         * 到找到一个没有左子节点的节点。这个节点就是最小值的节点。
         *      在学习删除节点之前,需要了解如何找到最小值的节点。
         *      按照相同的步骤来查找树中的最大值,不过要找到右子节点,一直向右找到没有右子节点的节
         * 点。这个节点就是最大值的节点。
         *
         * 删除节点
         *      删除节点是二叉搜索树常用的一般操作中最复杂的。但是,删除节点在很多树的应用中又非常
         * 重要,所以要详细研究并总结特点。
         *      删除节点要从查找要删的节点开始入手,方法与前面介绍的find()和 insert()相同。找到节点后,
         * 这个要删除的节点可能会有三种情况需要考虑:
         *      1.该节点是叶节点(没有子节点)。
         *      2.该节点有一个子节点。
         *      3.该节点有两个子节点。
         * 下面将依次讲解这三种情况。第一种最简单;第二种也还是比较简单的;而第三种就相当复杂
         * 了
         * - 情况1:删除没有子节点的节点
         *      要删除叶节点,只需要改变该节点的父节点的对应子字段的值,由指向该节点改为null就可以
         * 了。要删除的节点仍然存在,但它已经不是树的一部分了。
         *      因为Java语言有垃圾自动收集的机制,所以不需要非得把节点本身给删掉。一旦Java意识到
         * 程序不再与这个节点有关联,就会自动把它清理出存储器。(在C或C++语言中需要运行free或delete()
         * 方法来把节点从存储器中销毁)
         * - 情况2:删除有一个子节点的节点
         *      这第二种情况也不是很难。这个节点只有两个连接:连向父节点的和连向它惟一的子节点的
         * 需要从这个序列中“剪断”这个节点,把它的子节点直接连到它的父节点上。这个过程要求改变父
         * 节点适当的引用(左子节点还是右子节点),指向要删除节点的子节点。
         *  - 情况3:删除有两个子节点的节点
         *      删除有两个子节点的节点，用它的中序后继来代替该节点。
         *      对人来说,可以很快地找到节点的后继(不过也限于简单的树）。只要很快的扫一眼树,就可以找到比
         *  要删除节点大的下一个节点了。下面就是算法:
         *      首先,程序找到初始节点的右子节点,它的关键字值一定比初始节点大。然后转到初始节点的
         * 右子节点的左子节点那里(如果有的话),然后到这个左子节点的左子节点,以此类推,顺着左子
         * 节点的路径一直向下找。这个路径上的最后一个左子节点就是初始节点的后继。这里实际上是要找比初始节
         * 点关键值大的节点集合中最小的一个节点。当找到初始节点的右子节点时,这个以右子节点为根的子树的所有
         * 节点都比初始节点的关键字值大,因为这是二叉搜索树所定义的。现在要找到这棵子树中值最小的节点。因此,
         * 这个算法可以找到比初始节点大的最小的节点;它就是要找的后继。
         *      后继节点可能与current有两种位置关系, current就是要删除的节点。后继可能是 current的右子
         * 节点,或者也可能是 current右子节点的左子孙节点。下面来依次看看这两种情况。
         *  -- 后继节点是 delNode的右子节点
         *      如果后继是 current的右子节点,情况就简单了一点,因为只需要把后继为根的子树移到删除的
         * 节点的位置。此时current的左子节点肯定为null。
         *      1.把current从它父节点的rightChild字段删掉(当然也可能是leftChild字段),把这个字段指
         * 向后继。
         *      2.把 current的左子节点移出来,把它插到后继的 leftChild字段。
         * 下面是执行这两个步骤的代码语句,是从 delete()中摘出来的:
         *      1. parent.rightChild = successor;(或parent.leftChild = successor;)
         *      2. successor.leftchild = current.leftChild;
         *  -- 后继节点是delNode右子节点的左后代
         *      如果 Successor是要删除节点右子节点的左后代,执行删除操作需要以下四个步骤
         *      1.把后继父节点的 leftChild字段置为successor的右子节点
         *      2.把 successor的 rightChild字段置为要删除节点的右子节点。
         *      3.把current从它父节点的rightChild字段删掉(当然也可能是leftChild字段),把这个字段指
         * 向后继。
         *      4.把 current的左子节点移出来,把它插到后继的 leftChild字段。
         *      第1步和第2步由 getSuccessor()方法完成,第3步和第4步由 delete()方法完成。
         *                               50             <--parent
         *                                \
         *                                75            <--delNode/current
         *                              /    \
         *                             62    87         <--successorParent
         *                                 /    \
         *              successor-->     77     93
         *                                \
         *                                 79
         *
         *                               删除后
         *                               50
         *                                \
         *                                77
         *                              /    \
         *                             62    87
         *                                 /    \
         *                               79     93
         *
         *      1. successorParent.leftChild = successor.rightChild;
         *      2. successor.rightChild = delNode.rightChild;
         *      3. parent.rightChild = successor;(或parent.leftChild = successor;)
         *      4. successor.leftchild = current.leftChild;
         *
         * 删除是必要的吗?
         *      看到这里,就会发现删除是相当棘手的操作。实际上,因为它非常复杂,一些程序员都尝试着
         * 躲开它。他们在node类中加了一个 Boolean的字段,名称如 isDeleted。要删除一个节点时,就把此
         * 节点的这个字段置为true。其他操作,像 find(),在查找之前先判断这个节点是不是标志为已删除了。
         * 这样,删除的节点不会改变树的结构。当然,这样做存储中还保留着这种“已经删除”的节点
         *      这种方法或许有些逃避责任,但如果树中没有那么多删除操作时,这也不失为一个好方法。(例
         * 如,已经离职的员工的档案要永久保存在员工记录中。)
         *
         * 二叉树的效率
         *      正如前面看到的一样,树的大部分操作都需要从上到下一层一层地查找某个节点。它这样做要
         * 花多少时间呢?一棵满树中,大约一半的节点在最底层。(更确切地说,如果是满树,最底层的节
         * 点个数比树的其他节点数多1。)因此,查找、插入或删除节点的操作大约有一半都需要找到最底层
         * 的节点。(另外还有四分之一节点的这些操作要到倒数第二层,依次类推。)
         *      在查找过程中,需要访问每层的一个节点。所以只要知道有多少层就可以知道这些操作需要多
         * 长时间了。假设一棵满树,下表显示的就是容纳下给定数量节点所需要的层数。
         *      节点数                  层数
         * --------------------------------------------------
         *      1                       1
         *      3                       2
         *      7                       3
         *      15                      4
         *      31                      5
         *      ...                     ...
         *      1023                    10
         *      ...                     ...
         *      32767                   15
         *      ...                     ...
         *      1048575                 20
         *      ...                     ...
         * --------------------------------------------------------
         *      这个情况和第2章讨论的有序数组很相似。在第2章中,二分搜索比较的次数大致是数组中数
         * 据项个数的以2为底的对数。这里,设表中第一列节点个数为N,第二列层数为L,则N比2的L
         * 次方小1,即:
         *      N=2^L-1
         * 等式每边加1,得到:
         *      N+1=2^L
         * 这等于
         *      L=log2(N+1)
         *      因此,常见的树的操作时间复杂度大致是N以2为底的对数在大O表示法中,表示为O(logN)
         * 如果树不满,分析起来就很困难。不过,可以认为对给定层数的树,不满的树的平均查找时间
         * 比满树要短,因为它在较低的层上完成查找的次数要比满树时少。
         *      把树和前面讲过的那些数据结构做比较。在有100000个数据项的无序数组或链表中,查找数
         * 据项平均会比较5000次,但在有100000个节点的树中,只需要20(或更少)次的比较。
         *      有序数组可以很快的找到数据项,但插入数据项平均需要移动50000个数据项。在100000
         * 个节点的树中插入数据项需要20次或更少的比较,再加上很短的时间来连接数据项
         *      同样,从有100000个数据项的数组中删除一个数据项需要平均移动500000个数据项,而在
         * 1000000个节点的树中删除节点只需要20次或更少的比较来找到它,再加上(可能的话)一点比较
         * 的时间来找到它的后继,一点时间来断开这个节点的连接,以及连接它的后继
         *      因此,树对所有常用的数据存储操作都有很高的效率。
         *      遍历不如其他操作快。但是,遍历在大型数据库中不是常用的操作。它更常用于程序中的辅助
         * 方法来解析算术或其他的表达式,而且表达式一般都不会很长。
         */

        /**
         * 用数组表示树
         *      上面的实例代码基于这样的思想,树的边由每个节点的 leftChild和 rightChild字段中的引用表
         * 但是,还有一种完全不同的方法来表示树:用数组
         *      用数组的方法时,节点存在数组中,而不是由引用相连。节点在数组中的位置对应于它在树中
         * 的位置。下标为0的节点是根,下标为1的节点是根的左子节点,依次类推,按从左到右的顺序存
         * 储树的每一层。
         * 树中的每个位置,无论是否存在节点,都对应数组中的一个位置。把节点插入树的一个位置,意味着要在数组
         * 的相应位置插入一个数据项。树中没有节点的位置在数组中的对应位置用0或null来表示。
         *      基于这种思想,找节点的子节点和父节点可以利用简单的算术计算它们在数组中的索引值。设
         * 节点索引值为index,则节点的左子节点是:
         *      2*index +1
         * 它的右子节点是
         *      2*index+2
         * 它的父节点是
         *      (index-1)/2
         * (“/”符号表示整除运算)。
         *                          0
         *            /                            \
         *           1                              2
         *     /             \            /                    \
         *    3              4           5                      6
         *   / \            / \         / \                    / \
         *  7   8          9   10     11  12                 13   14
         *      大多数情况下用数组表示树不是很有效率。不满的节点和删除掉的节点在数组中留下了洞,浪
         * 费存储空间。更坏的是,删除节点时需要移动子树的话,子树中的每个节点都要移到数组中新的位
         * 置去,这在比较大的树中是很费时的。
         *      不过,如果不允许删除操作,数组表示可能会很有用,特别是因为某种原因要动态地为每个节
         * 点分配空间非常耗时。数组表示法在其他一些特殊的情况下也很有用。例如,专题 applet中的树,
         * 在内部就是由数组表示的,这样便于将数组中的节点画到屏幕上固定的位置上。
         *
         * 重复关键字
         *      和其他数据结构一样,重复关键字问题是必须要提到的。 insert()方法的代码中,以及在专题,
         * 有重复关键字的节点都插到与它关键字相同的节点的右子节点处
         *      问题是 find()方法具能找到两个(或多个)相同关键字节点中的第一个。可以修改find()方法来
         * 查找更多的数据项,区分有相同关键字的数据项,但这样做很(至少有点)消耗时间。
         * 一种选择是简单地禁止出现重复的关键字。当重复关键字通过数据的本身被排除了(例如,员
         * 工代码的数字),就不会存在问题了。
         *      否则,需要修改 Insert方法在插入过程中检查相同性,如果有相同的关键字时就放弃插入。
         */

        /**
         * 哈夫曼( Huffman)编码
         *      二叉树并不全是搜索树。很多二叉树用于其他的情况。图例如：二叉树表示了一个代数表
         * 达式。
         *      接下来讲解一个算法,它使用二叉树以令人惊讶的方式来压缩数据。1952年 David huffman发现
         * 这种方法后,就称它为哈夫曼编码。数据压缩在很多领域中都是非常重要的。例如要通过互联网发
         * 送数据,尤其是通过拨号连接时,传送过程要花很长时间。这种方法的实现是很冗长的,这里就不
         * 给出完整的程序了。而把重点放在概念上,***实现留作练习***
         * 字符编码
         *      计算机里每个字符在没有压缩的文本文件中由一个字节(如常见的ASCII码)或两个字节(如
         * 比较新的 Unicode,它可以在各种语言中通用)表示。这些方案中,每个字符需要相同的位数。
         *      有很多压缩数据的方法。对文本来说,最常用的方法是减少表示最常用字符的位数量。如英语
         * 中,E是最常用的字母,所以用尽可能少的位为E编码是很合理的。反之,z是很少用到的,所以
         * 用多些位表示也无所谓。
         *      假设只用两位表示E,如01。那么就不能给字典中其他每个字母都用两位编码了,因为2位只
         * 有四种组合:00、01、10和11。可以用这四种组合表示四个最常用的字符吗?
         *      很遗憾,不可以。必须小心的是,在编码序列中,如果用起始位组合相同的代码表示不同的字
         * 符,这样的情况是不能出现的。比如,如果E是01,而X是01011000,那么解码是就搞不清楚01011000
         * 起始的01是表示E还是表示X的开始部分了。这就产生了一个规则:每个代码都不能是其他代码
         * 的前缀。
         *      还有一些时候有的信息里E并不是最常用的字符。比如,文本是Java源代码的时候,分号“;”
         * 可能都比E出现的次数更多。下面就来解决这个问题:为每种信息根据其特别的信息定制新的编码。
         * 假设要发送消息: SUSIE SAYSIT IS EASY。字母S出现得最多,其次是空格。用表格来列出每种
         * 字符出现的次数。这样的表叫频率表。
         *                      频率表
         *          字符                      出现次数
         *    ----------------------------------------------------
         *          A                           2
         *          E                           2
         *          I                           3
         *          S                           6
         *          T                           1
         *          U                           1
         *          Y                           2
         *          空格                        4
         *          换行符                      1
         *    ---------------------------------------------------
         *      编码时，出现次数最多的字符所占位数应该最少。
         *                  哈夫曼编码
         *      字符                             编码
         *   ---------------------------------------------------
         *      A                               010
         *      E                               1111
         *      I                               110
         *      S                               10
         *      T                               0110
         *      U                               01111
         *      Y                               1110
         *      空格符                          00
         *      换行                            01110
         *  -----------------------------------------------------
         *      用10表示S,用00表示空格后,就不能再用01和11了,因为它们是其他字符的前缀。那三
         * 位的组合怎么办呢?三位的组合有8种可能性:000、001、010、011、100、101、110和111。A是
         * 010,I是110。为什么不能用其他组合呢?这是因为已知不能用由10或00开始的组合;这就减少
         * 了四种选择。同时,011用于U和换行符代码的开始,111用于E和Y的开始。这样就只有两个
         * 位代码留下来可以用了,它们就用来代表A和I。同样可以理解为什么只有三个四位代码可用。
         * 因此,整个消息编码后为
         *      10 01111 10 110 1111 00 10 010 1110 10 00 110 0110 00 110 10 00
         *      1111 010 10 1110 01110
         *      为了清楚,这里把这条消息的每个字符的代码分开显示。实际上所有位会连在一起;在二进制
         * 消息中没有空格字符,只有0和1。
         *
         * 用哈夫曼树解码
         *      稍后会看到如何建立哈夫曼编码。首先来看看简单一些的解码是怎么完成的。假设收到上节
         * 中的那条位字符串表示的消息。怎么才能把它转换回字符呢?可以使用一种叫做哈夫曼树的二
         * 叉树。
         *      消息中出现的字符在树中是叶节点。它们在消息中出现的频率越高,在树中的位置就越高
         * 每个圆圈外面的数字就是频率。非叶节点外面的数字是它子节点的频率的和。稍后会看到这样做
         * 的重要性。
         *      怎么用这棵树来解码呢?每个字符都从根开始。如果遇到0,就向左走到下个节点,如果
         * 遇到1,就向右。例如字符A的代码是010。先向左,向右,再向左,说也奇怪,这样就找到了
         * A节点。
         *      解码其他字符也是一样的过程。有耐心的话,可以用这方法把整个比特串都解码。
         *
         * 创建哈夫曼树
         *      上面已经学习了怎么用哈夫曼树解码,但怎么建立哈夫曼树呢?有很多方法来处理这个问题。
         * 本章的方法是基于tree代码程序中的Node类和Tree类(不过那些类中的应用于查找树的
         * 特殊方法,像 find()、insert()和 delete()都没有用了)。下面是建立哈夫曼树的算法
         *      1.为消息中的每个字符创建一个Node对象。每个节点有两个数据项:字符和字符在消息中出
         * 现的频率。
         *      2.为这些节点创建tree对象。这些节点就是树的根。
         *      3.把这些树都插入到一个优先级队列中(第4章中讲过)。它们按频率排序,频率最小的节点
         * 有最高的优先级。因此,删除一棵树的时候,它就是队中最少用到的字符
         *      现在做下面的事情
         *      1.从优先级队列中删掉两棵树,并把它们作为一个新节点的子节点。新节点的频率是子节点频
         * 率的和;它的字符字段可以是空的。
         *      2.把这个新的三节点树插回优先级队列里
         *      3.反复重复第一步和第二步。树会越变越大,队列中的数据项会越来越少。当队中只有一棵树
         * 时,它就是所建的哈夫曼树了。
         *
         * 信息编码
         *      现在建好了哈夫曼树,怎么为一段信息编码呢?从建立代码表开始,这个表中列出了每个字符的哈
         * 夫曼代码。为了简化讨论,假设计算机中不是用ASCI代码,而是用简化的字母表,只有28个字符的大写字
         * 母。A是0,B是1,一直到Z,是25。空格是26,换行符号是27。为这些字符按数字顺序编码,它们的代码从
         * 0到27。(这不是压缩编码,只是ASCII代码的简化,通常计算机中都是这么存储字符的。)
         *      代码表就是一个有28个单元的数组。每个单元的下标就是每个字符的数字编码:0是A,1是B,依此
         * 类推。单元的内容将是对应字符的哈夫曼编码。不是每个单元都有哈夫曼编码的
         * 只有出现在消息中的字符才会有。
         *      这样一个代码表就很方便编写信息的代码了:对每个原始消息中的每一个字符,都用代码表中对应
         * 的代码表示。然后再把对应的哈夫曼编码添加到信息的尾部,直到完成整个消息的代码转换为止。
         *
         * 创建哈夫曼编码
         *      怎样建立哈夫曼编码并把它插入代码表中呢?这个过程类似于对一条信息解码的过程。从哈夫
         * 曼树的根开始并顺着哈夫曼树沿一条可能的路径到达叶节点。在顺着树往下走时,记录向左和向右
         * 的顺序,向左的边用0表示,向右的边就用1表示。到达某个叶节点后,0和1的序列就是这个字
         * 符的哈夫曼编码。把这个代码插入代码表的正确位置就可以了。
         *      这个过程的实现可以从根开始调用一个方法,然后对它的每个子节点递归地调用方法本身。最
         * 后,所有到叶节点的路径都被遍历了,代码表也完成了。
         *
         * 哈夫曼编码实现看练习。
         */
    }

    public static void tree() {
        Tree theTree = new Tree();

        theTree.insert(50, 1.5);
        theTree.insert(25, 1.2);
        theTree.insert(75, 1.7);
        theTree.insert(12, 1.5);
        theTree.insert(37, 1.2);
        theTree.insert(43, 1.7);
        theTree.insert(30, 1.5);
        theTree.insert(33, 1.2);
        theTree.insert(87, 1.7);
        theTree.insert(93, 1.5);
        theTree.insert(97, 1.5);

        theTree.displayTree();
        theTree.insert(11, 11.9);
        theTree.insert(66, 66.9);

        theTree.displayTree();
        Node found = theTree.find(100);
        if(found != null)
        {
            System.out.print("Found: ");
            found.displayNode();
            System.out.print("\n");
        } else {
            System.out.println("not found 100");
        }

        found = theTree.find(37);
        if(found != null)
        {
            System.out.print("Found: ");
            found.displayNode();
            System.out.print("\n");
        } else {
            System.out.println("not found 37");
        }

        boolean didDelete = theTree.delete(33);
        if(didDelete)
            System.out.println("Deleted " + 33 + '\n');
        else
            System.out.println("Could not delete ");
        didDelete = theTree.delete(1000);
        if(didDelete)
            System.out.println("Deleted " + 1000 + '\n');
        else
            System.out.println("Could not delete ");

        theTree.displayTree();

        theTree.traverse(1);
        theTree.traverse(2);
        theTree.traverse(3);


        System.out.println("\n========================\n");
        theTree.displayTree2();
    }  // end main()
}
